Get money out of politics; reject any candidate who takes funding from Wallstreet or Pharma. Do not accept candidates who have served on the boards of major international corporations that exploit the tax code, exploit labor laws and trade agreements, circumvent human rights. These ties represent serious conflicts of interest. We cannot change the tax infrastructure if candidates are making deals with big donors because they think they need that money to get elected. They don't, and we need to reject and punish politicians that try to take that route. Just because we finally have 1 or 2 people in congress that are willing to stand for progressive policy doesn't mean the remaining hundreds don't need to be primaried and held accountable, and that we don't need to be scrupulous about who we elect.

but the best training environments with 300 words generalize to an additional 294 words (1252 vs 1546). A

Which training environments foster the most generalization?
While it is clear that some training sets outperform the mean by a large margin, it is difficult to characterize what the best training sets have in common. In an effort to do so, we ran several additional analyses. In these analyses, we have focused on training sets with 300 words, following from the analysis reported above.
Representativeness
We first hypothesized that training environments that included sets of words with representative orthographic and phonological spaces would foster models that generalize well. We fit autoencoder models to the orthographic and phonological representations, respectively, based on each of the 1 million training sets, yielding a total of 2 million autoencoders. We then assessed how well each orthographic and phonological autoencoder generalized to the untrained words in the corpus. This generalization accuracy was taken to express orthographic and phonological representativeness.
The orth-to-phon generalization performance was then regressed on the orthographic and phonological representativeness. To our surprise, this explained almost no variance in the accuracy distribution. Further, we fit a classifier with logistic regression to discriminate between the top and bottom 5% of the accuracy distribution based on a linear combination of orthographic and phonological representativeness. This classifier was only accurate 68% of the time (chance 50%), indicating that representativeness may be important, but certainly not decisive.
Difficulty


The role of quality and quantity
    Learning the ortho-phonological system can easily be cast as a matter of the quality and quantity of what the child needs to be exposed to in the printed language environment in order to learn what she needs to in order to generalize to new printed words. The role of quantity and quality has a rich history in developmental science, especially in the language domain (Hart & Risley, 1995; Hirsch-Pasek et al., 2015; Weisleder & Fernald, 2013). Educators have long toiled about the quantity and characteristics of printed language input that a child ought to be exposed to in service of developing basic reading skills. Chang et al. (2017) found using a connectionist model, varying the amount of oral vocabulary knowledge mediated the effects of orthography-phonology (OP) training in the model, such that OP training was only useful to the learner when requisite oral vocabulary knowledge was in place. Experiments designed to examine environment-level manipulations are not easy to implement given the scale of learning over time, and the variety of learning that can occur over such a period.
    The history of research in education in this area has been dictated primarily by principles that might support the development of relevant knowledge in the print domain. For example, phonemic awareness is long thought to be the sine qua non of basic reading skill development. If an educator or designer of educational materials takes phonemic awareness as the essential component of success in learning to read in an educational setting, one might select words that exhibit clear mappings between the printed and spoken forms of words. In this case the “cat” and “ball” instructional regimen could very well be the way to go. Determining such a course of learning (or a “curriculum”), while being constructed in a principled manner, likely may not optimize learning based on what we know about learning from relevant developmental theories.
Teaching, but for machines
In related research in computer sciences there is a growing body of research that casts machine learning in a modeling enterprise oriented towards  optimizing the environment in which models learn, dubbed machine teaching (Bengio, Louradour, Collobert, & Weston, 2009; Zhu, 2016). The machine teaching approach is to posit a model of a learner and, in turn, investigate the optimal training set to support learning (Zhu, 2015). This computational approach has been applied in a limited way to developmental outcomes, including educational ones (Liu et al., 2017; Sen et al., 2018), though none related to reading development. These methods could easily be applied to the problem of understanding the learning environments that support knowledge development of the print-to-sound mappings in English, which is the focus of the studies described here.
    Our approach attempts to capitalize on the machine teaching approach with regard to two important but related matters in child development. First, how does the quantity of trained printed words lead to different levels of generalization for the models trained? Second, does the quality of the training set produce variable patterns of generalization within a given training set size. An extension of this latter question not addressed here (but is nonetheless relevant) is whether the effect of quality is modulated by training set size and is the topic of future work not discussed here.
